{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-9mL7lXz0mo",
        "metadata": {},
        "outputId": "141835d1-fab1-45fa-85df-32f532ece3da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping pennylane as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch torchvision\n",
        "!pip uninstall pennylane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VpMjoE3v-nE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPX9br7jwbmH"
      },
      "source": [
        "# Data Preparation and Loading\n",
        "\n",
        "Use the MNIST dataset: https://en.wikipedia.org/wiki/CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tc7SzbpwVgP",
        "outputId": "3d7ba899-b976-4668-82f7-4990f2cb25df"
      },
      "outputs": [],
      "source": [
        "# Download and load MNIST dataset\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    download = True,\n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    transform = ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRwUYemCyrYU"
      },
      "source": [
        "# Creating the CNN Architecture\n",
        "\n",
        "The CNN architecture is defined with two convolutional layers, max pooling layers, and fully connected layers. The forward method specifies how data flows through the network. This architecture is suitable for image classification tasks and can be modified to suit your specific project requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhFmkPj-yvHw"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pennylane as qml\n",
        "\n",
        "# Define the quantum circuit using PennyLane\n",
        "n_qubits = 5\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def qnode(inputs, weights):\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
        "\n",
        "# Define the QLayer\n",
        "n_layers = 3\n",
        "weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
        "\n",
        "\n",
        "# Define a simple CNN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Convolutional layer 1 with 1 input channels (for greyscale images), 16 output channels, and 5x5 kernel\n",
        "        self.conv1 = nn.Conv2d(1, 16, 5, stride=1, padding=2)\n",
        "        # Batch normalization after convolutional layer 1\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        # Max pooling layer with a 2x2 window\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # Convolutional layer 2 with 16 input channels (from the previous layer), 32 output channels, and 5x5 kernel\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5, stride=1, padding=2)\n",
        "        # Batch normalization after convolutional layer 2\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        # Quantum layer\n",
        "        self.qlayer1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "        self.qlayer2 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "        self.qlayer3 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "        self.qlayer4 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(32 * 7 * 7, 120)\n",
        "        self.fc2 = nn.Linear(120, 20)\n",
        "        self.fc3 = nn.Linear(20, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Propagate the input through the CNN layers\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        # Flatten the output from the convolutional layers\n",
        "        x = x.view(-1, 32 * 7 * 7)\n",
        "        # Pass the output to the quantum layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x_1, x_2, x_3, x_4 = torch.split(x, 5, dim=1)\n",
        "        x_1 = self.qlayer1(x_1)\n",
        "        x_2 = self.qlayer2(x_2)\n",
        "        x_3 = self.qlayer3(x_3)\n",
        "        x_4 = self.qlayer4(x_4)\n",
        "        x = torch.cat([x_1, x_2, x_3, x_4], axis=1)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7i8G2szzSxz"
      },
      "source": [
        "# Train the CNN\n",
        "\n",
        "The CNN model is initialised, the loss function and optimizer are set up, and data loaders for training and validation data are created. The training loop iterates through the dataset for a specified number of epochs, performing forward and backward passes to update the modelâ€™s parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8a6qGcOzV_1"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from tqdm import tqdm\n",
        "dataset  = train_data\n",
        "\n",
        "# Initialize your CNN model\n",
        "cnn = Net()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)  # Stochastic Gradient Descent optimizer\n",
        "# Split your data into training and validation sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True)\n",
        "#val_loader = torch.utils.data.DataLoader(val_set, batch_size=4, shuffle=False)\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    ct = datetime.datetime.now()\n",
        "    print(f\"{epoch=}, {ct}\")\n",
        "    running_loss = 0.0\n",
        "    progress_bar = tqdm(enumerate(train_loader, 0), total=len(train_loader))\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()  # Zero the parameter gradients to avoid accumulation\n",
        "        outputs = cnn(inputs)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute the loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update the model parameters\n",
        "        running_loss += loss.item()\n",
        "        progress_bar.set_postfix({'loss': running_loss / (i + 1)})\n",
        "print('Finished Training')\n",
        "# Save the model\n",
        "torch.save(cnn.state_dict(), 'model.pth')\n",
        "print('Saved trained model')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dAn7ec12RgV"
      },
      "source": [
        "# Evaluating the Model\n",
        "\n",
        "Set the model to evaluation mode, use it to make predictions on the validation dataset, and calculate the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6eYQIjr2erR"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=4, shuffle=False)\n",
        "# Set the model to evaluation mode\n",
        "cnn.eval()\n",
        "with torch.no_grad():\n",
        "    for data in val_loader:\n",
        "        images, labels = data\n",
        "        outputs = cnn(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy on the validation set: {100 * correct / total:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
